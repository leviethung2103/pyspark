{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
    "\n",
    "# Find the spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/content/original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the null\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# replace the null value in column City, and create new colum namned clean_city\n",
    "mydata2 = mydata.withColumn('clean_city', when(mydata.City.isNull(), 'Unknown').otherwise(mydata.City))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter value in colum is not null\n",
    "mydata2 = mydata2.filter(mydata2.JobTitle.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first character\n",
    "mydata2 = mydata2.withColumn('clean_salary', mydata2.Salary.substr(2,100).cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average clean_salary\n",
    "mean = mydata2.groupBy().avg('clean_salary')\n",
    "mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because mean is data frame -> take the fist row + first column\n",
    "mean = mydata2.groupBy().avg('clean_salary').take(1)[0][0] # first row and first column\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# replace null value with mean value\n",
    "mydata2 = mydata2.withColumn('new_salary', when(mydata2.clean_salary.isNull(), mean).otherwise(mydata2.clean_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# filter latitudes isNotNul()\n",
    "latitudes = latitudes.filter(latitudes.Latitude.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to float\n",
    "latitudes = latitudes.withColumn('latitude2', latitudes.Latitude.cast('float')).select('latitude2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the median\n",
    "median = np.median(latitudes.collect())\n",
    "print(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the null values in Latitude with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_above_average = mydata2.filter((mydata2.gender == \"Male\") & (mydata2.clean_salary > mean_salary)).count()\n",
    "women_above_average = mydata2.filter((mydata2.gender == \"Women\") & (mydata2.clean_salary > mean_salary)).count()\n",
    "\n",
    "# Print the results\n",
    "if men_above_average > women_above_average:\n",
    "  print(\"Men are more likely to earn more than the average salary.\")\n",
    "elif women_above_average > men_above_average:\n",
    "  print(\"Women are more likely to earn more than the average salary.\")\n",
    "else:\n",
    "  print(\"Men and women are equally likely to earn more than the average salary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sqlfunc\n",
    "\n",
    "genders = mydata2.groupBy('gender').agg(sqlfunc.avg('new_salary').alias('avg_salary'))\n",
    "genders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mydata2.withColumn('female_salary', when(mydata2.gender == 'Female', mydata2.new_salary).otherwise(lit(0)))\n",
    "df = df.withColumn('male_salary', when(mydata2.gender == 'Male', mydata2.new_salary).otherwise(lit(0)))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupBy('JobTitle').agg(sqlfunc.avg('female_salary').alias('avg_female_salary'), sqlfunc.avg('male_salary').alias('avg_male_salary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('delta', df.avg_female_salary - df.avg_male_salary)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find down which cities has the highest average salary\n",
    "cityavg = mydata2.groupBy('City').agg(sqlfunc.avg('new_salary').alias('final_avg_salary'))\n",
    "cityavg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the final_avg_salary form high to low\n",
    "sorted_cityavg = cityavg.sort(desc('final_avg_salary'))\n",
    "sorted_cityavg.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
